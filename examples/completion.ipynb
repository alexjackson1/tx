{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jaxtyping import Array\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "from tx.models.gpt2 import PretrainedGPT2Model\n",
    "from tx.hooks import HookPoint, Hook\n",
    "from tx.network import GenerativeModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PretrainedGPT2Model.tx_config\n",
    "config.decode = True\n",
    "\n",
    "\n",
    "def store_hook(x, module: nn.Module, hook_point: HookPoint):\n",
    "    module.sow(\"intermediates\", hook_point.value, x)\n",
    "    return x\n",
    "\n",
    "\n",
    "reference_gpt2 = GenerativeModel(\n",
    "    config=config,\n",
    "    tokenizer=GPT2TokenizerFast.from_pretrained(\"gpt2\"),\n",
    "    params=PretrainedGPT2Model.from_pretrained(\"gpt2\").to_params(),\n",
    "    hooks={HookPoint.ATTN_OUTPUT.value: Hook(store_hook)},\n",
    "    hook_collections=[\"intermediates\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256 15496    11   314   716]\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"Hello, I am\"\n",
    "tokens: Array = reference_gpt2.to_tokens(reference_text, prepend_bos=True)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reference_gpt2.to_str(tokens), end=\"\", flush=True)\n",
    "# for i in range(tokens.shape[0]):\n",
    "#     # Pass sequence through the model to get new output\n",
    "#     logits, _ = reference_gpt2(tokens[: i + 1])\n",
    "#     # Get the predicted token at the end of our sequence\n",
    "#     next_token = jnp.argmax(logits, axis=-1)[-1]\n",
    "#     # Decode and print the result\n",
    "#     next_char = reference_gpt2.to_str(next_token)\n",
    "#     print(f\"next_token[{i}]: {next_char}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    }
   ],
   "source": [
    "logits, _ = reference_gpt2(tokens)\n",
    "next_token = jnp.argmax(jax.nn.softmax(logits), axis=-1)[-1]\n",
    "next_char = reference_gpt2.to_str(next_token)\n",
    "print(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n",
      " student\n",
      " at\n",
      " the\n",
      " University\n",
      " of\n",
      " California\n",
      ",\n",
      " Berkeley\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "cur_tokens = tokens\n",
    "for i in range(10):\n",
    "    # Pass sequence through the model to get new output\n",
    "    logits, _ = reference_gpt2(cur_tokens)\n",
    "    # Get the predicted token at the end of our sequence\n",
    "    next_token = jnp.argmax(logits, axis=-1)[-1]\n",
    "    # Decode and print the result\n",
    "    next_char = reference_gpt2.to_str(next_token)\n",
    "    print(next_char)\n",
    "    # Define new input sequence, by appending the previously generated token\n",
    "    cur_tokens = jnp.append(cur_tokens, next_token)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b805f1a24a146351cd8dedea7ba6f2d165b63b34e3029cd12d1a8f2ce65f719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
