{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jaxtyping import Array\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "from tx.models.gpt2 import PretrainedGPT2Model\n",
    "from tx.hooks import HookPoint, StoreHook\n",
    "from tx.network import GenerativeModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:40:23.474561: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:276] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "CUDA backend failed to initialize: FAILED_PRECONDITION: No visible GPU devices. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "config = PretrainedGPT2Model.tx_config\n",
    "config.decode = True\n",
    "\n",
    "\n",
    "reference_gpt2 = GenerativeModel(\n",
    "    config=config,\n",
    "    tokenizer=GPT2TokenizerFast.from_pretrained(\"gpt2\"),\n",
    "    params=PretrainedGPT2Model.from_pretrained(\"gpt2\").to_params(),\n",
    "    hooks={HookPoint.ATTN_OUTPUT.value: StoreHook},\n",
    "    hook_collections=[\"intermediates\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256 15496    11   314   716]\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"Hello, I am\"\n",
    "tokens: Array = reference_gpt2.to_tokens(reference_text, prepend_bos=True)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reference_gpt2.to_str(tokens), end=\"\", flush=True)\n",
    "# for i in range(tokens.shape[0]):\n",
    "#     # Pass sequence through the model to get new output\n",
    "#     logits, _ = reference_gpt2(tokens[: i + 1])\n",
    "#     # Get the predicted token at the end of our sequence\n",
    "#     next_token = jnp.argmax(logits, axis=-1)[-1]\n",
    "#     # Decode and print the result\n",
    "#     next_char = reference_gpt2.to_str(next_token)\n",
    "#     print(f\"next_token[{i}]: {next_char}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    }
   ],
   "source": [
    "logits, _ = reference_gpt2(tokens)\n",
    "next_token = jnp.argmax(jax.nn.softmax(logits), axis=-1)[-1]\n",
    "next_char = reference_gpt2.to_str(next_token)\n",
    "print(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>Hello, I am a student at the University of California, Berkeley."
     ]
    }
   ],
   "source": [
    "cur_tokens = tokens\n",
    "print(reference_gpt2.to_str(cur_tokens), end=\"\", flush=True)\n",
    "for i in range(10):\n",
    "    # Pass sequence through the model to get new output\n",
    "    logits, _ = reference_gpt2(cur_tokens)\n",
    "    # Get the predicted token at the end of our sequence\n",
    "    next_token = jnp.argmax(logits, axis=-1)[-1]\n",
    "    # Decode and print the result\n",
    "    next_char = reference_gpt2.to_str(next_token)\n",
    "    print(next_char, end=\"\", flush=True)\n",
    "    # Define new input sequence, by appending the previously generated token\n",
    "    cur_tokens = jnp.append(cur_tokens, next_token)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b805f1a24a146351cd8dedea7ba6f2d165b63b34e3029cd12d1a8f2ce65f719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
