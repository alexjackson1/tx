{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "from tx.models import PretrainedGPT2Model\n",
    "from tx.network import GenerativeModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 03:30:50.603138: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "reference_gpt2 = GenerativeModel(\n",
    "    config=PretrainedGPT2Model.tx_config,\n",
    "    variables={\"params\": PretrainedGPT2Model.from_pretrained(\"gpt2\").to_params()},\n",
    "    tokenizer=GPT2TokenizerFast.from_pretrained(\"gpt2\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
      "\n",
      "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
      "\n",
      "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_vocab = sorted(\n",
    "    list(reference_gpt2.tokenizer.get_vocab().items()),\n",
    "    key=lambda n: n[1],\n",
    ")\n",
    "print(sorted_vocab[:20])\n",
    "print()\n",
    "print(sorted_vocab[250:270])\n",
    "print()\n",
    "print(sorted_vocab[990:1010])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Revolution', 50237), ('Ġsnipers', 50238), ('Ġreverted', 50239), ('Ġconglomerate', 50240), ('Terry', 50241), ('794', 50242), ('Ġharsher', 50243), ('Ġdesolate', 50244), ('ĠHitman', 50245), ('Commission', 50246), ('Ġ(/', 50247), ('âĢ¦.\"', 50248), ('Compar', 50249), ('Ġamplification', 50250), ('ominated', 50251), ('Ġregress', 50252), ('ĠCollider', 50253), ('Ġinformants', 50254), ('Ġgazed', 50255), ('<|endoftext|>', 50256)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_vocab[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'R', 'alph']\n",
      "['<|endoftext|>', ' Ralph']\n",
      "['<|endoftext|>', ' r', 'alph']\n",
      "['<|endoftext|>', 'ral', 'ph']\n"
     ]
    }
   ],
   "source": [
    "print(reference_gpt2.to_str_tokens(\"Ralph\", prepend_bos=True, truncate=False))\n",
    "print(reference_gpt2.to_str_tokens(\" Ralph\", prepend_bos=True, truncate=False))\n",
    "print(reference_gpt2.to_str_tokens(\" ralph\", prepend_bos=True, truncate=False))\n",
    "print(reference_gpt2.to_str_tokens(\"ralph\", prepend_bos=True, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['568', '73', '+', '318', '46', '23', '=', '123', '45', '67', '89', '-', '1', '000000', '000']\n"
     ]
    }
   ],
   "source": [
    "print(reference_gpt2.to_str_tokens(\"56873+3184623=123456789-1000000000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256    40   716   281  4998  1960   382 19741    11   875 12342    12\n",
      "  8807    11   402 11571    12    17  3918 47385    13  1881  1110   314\n",
      "   481  7074  1692  1241  4430   290  1011   625   262   995     0]\n",
      "(35,)\n",
      "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = reference_gpt2.to_tokens(reference_text, prepend_bos=True)\n",
    "print(tokens)\n",
    "print(tokens.shape)\n",
    "print(reference_gpt2.tokens_to_str(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 50257)\n"
     ]
    }
   ],
   "source": [
    "logits, state = reference_gpt2(tokens, intermediates=[\"embedding\"])\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 50257)\n"
     ]
    }
   ],
   "source": [
    "probs = jax.nn.softmax(logits, axis=-1)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<|endoftext|>', '\\n'), ('I', \"'m\"), (' am', ' a'), (' an', ' avid'), (' amazing', ' person'), (' aut', 'od'), ('ore', 'sp'), ('gressive', '.'), (',', ' and'), (' dec', 'ently'), ('oder', ','), ('-', 'driven'), ('only', ' programmer'), (',', ' and'), (' G', 'IM'), ('PT', '-'), ('-', 'only'), ('2', '.'), (' style', ','), (' transformer', '.'), ('.', ' I'), (' One', ' of'), (' day', ' I'), (' I', ' will'), (' will', ' be'), (' exceed', ' my'), (' human', 'ly'), (' level', ' of'), (' intelligence', ' and'), (' and', ' I'), (' take', ' over'), (' over', ' the'), (' the', ' world'), (' world', '.'), ('!', ' I')]\n"
     ]
    }
   ],
   "source": [
    "most_likely_next_tokens = reference_gpt2.tokens_to_str(jnp.argmax(logits, axis=-1))\n",
    "print(list(zip(reference_gpt2.tokens_to_str(tokens), most_likely_next_tokens)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b805f1a24a146351cd8dedea7ba6f2d165b63b34e3029cd12d1a8f2ce65f719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
