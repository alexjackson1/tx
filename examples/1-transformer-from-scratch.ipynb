{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer from Scratch\n",
    "\n",
    "Reimplementation of Transformer from Scratch using JAX and tx, original notebook by Callum McDougall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:24.926875362Z",
     "start_time": "2023-09-10T05:26:24.869677090Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Inputs and Outputs of a Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:25.403495857Z",
     "start_time": "2023-09-10T05:26:24.925717866Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import math\n",
    "import re\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import einops\n",
    "from jaxtyping import Array, Float, Int\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tx.models import PretrainedGPT2Model\n",
    "from tx.network import GenerativeModel\n",
    "from tx.intermediates import AllIntermediates\n",
    "import tx.modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:32.087644665Z",
     "start_time": "2023-09-10T05:26:25.405309541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 13:20:29.000194: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "reference_gpt2 = GenerativeModel(\n",
    "    config=PretrainedGPT2Model.tx_config,\n",
    "    variables={\"params\": PretrainedGPT2Model.from_pretrained(\"gpt2\").to_params()},\n",
    "    tokenizer=GPT2TokenizerFast.from_pretrained(\"gpt2\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:32.166481780Z",
     "start_time": "2023-09-10T05:26:32.164941362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
      "\n",
      "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
      "\n",
      "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_vocab = sorted(\n",
    "    list(reference_gpt2.tokenizer.get_vocab().items()),\n",
    "    key=lambda n: n[1],\n",
    ")\n",
    "print(sorted_vocab[:20])\n",
    "print()\n",
    "print(sorted_vocab[250:270])\n",
    "print()\n",
    "print(sorted_vocab[990:1010])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:32.170814861Z",
     "start_time": "2023-09-10T05:26:32.166617496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Revolution', 50237), ('Ġsnipers', 50238), ('Ġreverted', 50239), ('Ġconglomerate', 50240), ('Terry', 50241), ('794', 50242), ('Ġharsher', 50243), ('Ġdesolate', 50244), ('ĠHitman', 50245), ('Commission', 50246), ('Ġ(/', 50247), ('âĢ¦.\"', 50248), ('Compar', 50249), ('Ġamplification', 50250), ('ominated', 50251), ('Ġregress', 50252), ('ĠCollider', 50253), ('Ġinformants', 50254), ('Ġgazed', 50255), ('<|endoftext|>', 50256)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_vocab[-20:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:32.232348717Z",
     "start_time": "2023-09-10T05:26:32.171390476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'R', 'alph']\n",
      "['<|endoftext|>', ' Ralph']\n",
      "['<|endoftext|>', ' r', 'alph']\n",
      "['<|endoftext|>', 'ral', 'ph']\n"
     ]
    }
   ],
   "source": [
    "print(reference_gpt2.to_str_list(\"Ralph\", prepend_bos=True, truncate=False))\n",
    "print(reference_gpt2.to_str_list(\" Ralph\", prepend_bos=True, truncate=False))\n",
    "print(reference_gpt2.to_str_list(\" ralph\", prepend_bos=True, truncate=False))\n",
    "print(reference_gpt2.to_str_list(\"ralph\", prepend_bos=True, truncate=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:32.272518593Z",
     "start_time": "2023-09-10T05:26:32.231252538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['568', '73', '+', '318', '46', '23', '=', '123', '45', '67', '89', '-', '1', '000000', '000']\n"
     ]
    }
   ],
   "source": [
    "print(reference_gpt2.to_str_list(\"56873+3184623=123456789-1000000000\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:32.359439447Z",
     "start_time": "2023-09-10T05:26:32.274652184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256    40   716   281  4998  1960   382 19741    11   875 12342    12\n",
      "  8807    11   402 11571    12    17  3918 47385    13  1881  1110   314\n",
      "   481  7074  1692  1241  4430   290  1011   625   262   995     0]\n",
      "(35,)\n",
      "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = reference_gpt2.to_tokens(reference_text, prepend_bos=True)\n",
    "print(tokens)\n",
    "print(tokens.shape)\n",
    "print(reference_gpt2.to_str_list(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:33.022075741Z",
     "start_time": "2023-09-10T05:26:32.358809253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 50257)\n"
     ]
    }
   ],
   "source": [
    "logits, state = reference_gpt2.run_with_intermediates(tokens, intermediates=AllIntermediates)\n",
    "print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:33.111822337Z",
     "start_time": "2023-09-10T05:26:33.024667605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 50257)\n"
     ]
    }
   ],
   "source": [
    "probs: Array = jax.nn.softmax(logits, axis=-1)\n",
    "print(probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:33.162448945Z",
     "start_time": "2023-09-10T05:26:33.117037794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<|endoftext|>', '\\n'), ('I', \"'m\"), (' am', ' a'), (' an', ' avid'), (' amazing', ' person'), (' aut', 'od'), ('ore', 'sp'), ('gressive', '.'), (',', ' and'), (' dec', 'ently'), ('oder', ','), ('-', 'driven'), ('only', ' programmer'), (',', ' and'), (' G', 'IM'), ('PT', '-'), ('-', 'only'), ('2', '.'), (' style', ','), (' transformer', '.'), ('.', ' I'), (' One', ' of'), (' day', ' I'), (' I', ' will'), (' will', ' be'), (' exceed', ' my'), (' human', 'ly'), (' level', ' of'), (' intelligence', ' and'), (' and', ' I'), (' take', ' over'), (' over', ' the'), (' the', ' world'), (' world', '.'), ('!', ' I')]\n"
     ]
    }
   ],
   "source": [
    "most_likely_next_tokens = reference_gpt2.to_str_list(jnp.argmax(logits, axis=-1))\n",
    "print(list(zip(reference_gpt2.to_str_list(tokens), most_likely_next_tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:33.205778360Z",
     "start_time": "2023-09-10T05:26:33.162027189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' I'\n"
     ]
    }
   ],
   "source": [
    "next_token = jnp.argmax(logits[-1], axis=-1, keepdims=True)\n",
    "next_char = reference_gpt2.to_str(next_token)\n",
    "print(repr(next_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T05:26:33.206099232Z",
     "start_time": "2023-09-10T05:26:33.205328282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world! I(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      "(36, 768)\n",
      " am(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      "(37, 768)\n",
      " a(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      "(38, 768)\n",
      " very(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      "(39, 768)\n",
      " talented(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      "(40, 768)\n",
      " and(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      "(41, 768)\n",
      " talented(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      "(42, 768)\n",
      " person(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      "(43, 768)\n",
      ",(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      "(44, 768)\n",
      " and(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n",
      "(45, 768)\n"
     ]
    }
   ],
   "source": [
    "print(reference_gpt2.to_str(tokens), end=\"\", flush=True)\n",
    "\n",
    "for i in range(10):\n",
    "    print(next_char, end=\"\", flush=True)\n",
    "    # Define new input sequence, by appending the previously generated token\n",
    "    tokens = jnp.concatenate([tokens, next_token], axis=-1)\n",
    "    # # Pass our new sequence through the model, to get new output\n",
    "    logits = reference_gpt2(tokens)\n",
    "    # # Get the predicted token at the end of our sequence\n",
    "    next_token = jnp.argmax(logits[-1], axis=-1, keepdims=True)\n",
    "    # # Decode and print the result\n",
    "    next_char = reference_gpt2.to_str(next_token)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Transformer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding: (35, 768).\n",
      "positional_embedding: (35, 768).\n",
      "residual: (35, 768).\n",
      "block_0:\n",
      "  ln_1_output: (35, 768).\n",
      "  attn:\n",
      "    query: (35, 12, 64).\n",
      "    key: (35, 12, 64).\n",
      "    value: (35, 12, 64).\n",
      "    scores: (12, 35, 35).\n",
      "    pattern: (12, 35, 35).\n",
      "    z: (35, 12, 64).\n",
      "  attention_output: (35, 768).\n",
      "  ln_2_output: (35, 768).\n",
      "  mlp:\n",
      "    pre_activation: (35, 3072).\n",
      "    post_activation: (35, 3072).\n",
      "final_output: (35, 768).\n"
     ]
    }
   ],
   "source": [
    "def p(x, indent=0):\n",
    "    if isinstance(x, dict):\n",
    "        for k, v in x.items():\n",
    "            # test regex here\n",
    "            matches = re.findall(r\"block_(\\d+)\", k)\n",
    "            if matches and matches[0] != \"0\":\n",
    "                continue\n",
    "\n",
    "            print(f\"{'  ' * indent}{k}\", end=\"\")\n",
    "            if isinstance(v, dict):\n",
    "                print(\":\")\n",
    "                p(v, indent=indent + 1)\n",
    "            else:\n",
    "                print(f\": \", end=\"\")\n",
    "                p(v)\n",
    "    elif isinstance(x, list):\n",
    "        p(x[0])\n",
    "    elif isinstance(x, tuple):\n",
    "        p(x[0])\n",
    "    elif isinstance(x, Array):\n",
    "        print(f\"{' ' * indent}{x.shape}.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown type: {type(x)}\")\n",
    "\n",
    "\n",
    "p(state[\"intermediates\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed:\n",
      "  embedding: (50257, 768).\n",
      "pos_embed:\n",
      "  embedding: (1024, 768).\n",
      "block_0:\n",
      "  ln_1:\n",
      "    bias: (768,).\n",
      "    scale: (768,).\n",
      "  attn:\n",
      "    c_attn:\n",
      "      kernel: (768, 2304).\n",
      "      bias: (2304,).\n",
      "    c_proj:\n",
      "      kernel: (768, 768).\n",
      "      bias: (768,).\n",
      "  ln_2:\n",
      "    bias: (768,).\n",
      "    scale: (768,).\n",
      "  mlp:\n",
      "    fc_1:\n",
      "      kernel: (768, 3072).\n",
      "      bias: (3072,).\n",
      "    proj:\n",
      "      kernel: (3072, 768).\n",
      "      bias: (768,).\n",
      "ln_f:\n",
      "  bias: (768,).\n",
      "  scale: (768,).\n",
      "unembed:\n",
      "  kernel: (768, 50257).\n",
      "  bias: (50257,).\n"
     ]
    }
   ],
   "source": [
    "p(reference_gpt2.variables[\"params\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerConfig(vocab_dim=50257, context_length=1024, model_dim=768, num_layers=12, num_heads=12, head_dim=64, mlp_dim=3072, layer_norm_eps=1e-05, init_range=0.02)\n"
     ]
    }
   ],
   "source": [
    "print(reference_gpt2.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(model_dim=768, debug=True, layer_norm_eps=1e-05, vocab_dim=50257, init_range=0.02, context_length=1024, head_dim=64, mlp_dim=3072, num_heads=12, num_layers=12)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    model_dim: int = 768\n",
    "    debug: bool = True\n",
    "    layer_norm_eps: float = 1e-5\n",
    "    vocab_dim: int = 50257\n",
    "    init_range: float = 0.02\n",
    "    context_length: int = 1024\n",
    "    head_dim: int = 64\n",
    "    mlp_dim: int = 3072\n",
    "    num_heads: int = 12\n",
    "    num_layers: int = 12\n",
    "\n",
    "\n",
    "ex_cfg = Config()\n",
    "print(ex_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.random as jr\n",
    "\n",
    "\n",
    "def rand_float_test(cls, shape):\n",
    "    layer = cls(Config(debug=True))\n",
    "    random_input: Array = jr.uniform(jr.PRNGKey(0), shape)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "\n",
    "    variables = layer.init(jr.PRNGKey(0), random_input)\n",
    "    output: Array = layer.apply(variables, random_input)\n",
    "    print(\"Output shape:\", output.shape, \"\\n\")\n",
    "\n",
    "\n",
    "def rand_int_test(cls, shape):\n",
    "    layer = cls(Config(debug=True))\n",
    "    random_input: Array = jr.randint(jr.PRNGKey(0), shape, minval=100, maxval=1000)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "\n",
    "    variables = layer.init(jr.PRNGKey(0), random_input)\n",
    "    output: Array = layer.apply(variables, random_input)\n",
    "    print(\"Output shape:\", output.shape, \"\\n\")\n",
    "\n",
    "\n",
    "def load_gpt2_test(cls, ref_cls, ref_cfg, variables, x: Array, ref_vars=None):\n",
    "    # Initialise the layer to test\n",
    "    layer = cls(cfg=Config(debug=True))\n",
    "    print(\"Input shape:\", x.shape)\n",
    "\n",
    "    # Apply the layer to the input\n",
    "    output = layer.apply(variables, x)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "\n",
    "    # Initialise the reference layer to test against\n",
    "    # nn.vmap is used to apply the layer to each element of the batch\n",
    "    ref_layer = nn.vmap(\n",
    "        ref_cls,\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "        variable_axes={\"params\": None},\n",
    "        split_rngs={\"params\": False},\n",
    "    )(**ref_cfg)\n",
    "\n",
    "    # Apply the reference layer to the input\n",
    "    if ref_vars is None:\n",
    "        reference_output = ref_layer.apply(variables, x)\n",
    "    else:\n",
    "        reference_output = ref_layer.apply(ref_vars, x)\n",
    "    print(\"Reference output shape:\", reference_output.shape, \"\\n\")\n",
    "\n",
    "    # Compare the output of the layer to the reference output\n",
    "    comparison = jnp.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
    "    print(\n",
    "        f\"{jnp.sum(comparison) / jnp.size(comparison):.2%} of the values are correct\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "gpt2_params = reference_gpt2.variables[\"params\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 4, 768)\n",
      "Output shape: (2, 4, 768) \n",
      "\n",
      "Input shape: (1, 35, 768)\n",
      "Output shape: (1, 35, 768)\n",
      "Reference output shape: (1, 35, 768) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        self.w = self.param(\"w\", nn.initializers.ones, (self.cfg.model_dim,))\n",
    "        self.b = self.param(\"b\", nn.initializers.zeros, (self.cfg.model_dim,))\n",
    "\n",
    "    def __call__(\n",
    "        self, residual: Float[Array, \"batch seq model\"]\n",
    "    ) -> Float[Array, \"batch seq model\"]:\n",
    "        residual_mean = jnp.mean(residual, axis=-1, keepdims=True)\n",
    "        residual_std = jnp.sqrt(\n",
    "            jnp.var(residual, axis=-1, keepdims=True) + self.cfg.layer_norm_eps\n",
    "        )\n",
    "\n",
    "        residual = (residual - residual_mean) / residual_std\n",
    "        return residual * self.w + self.b\n",
    "\n",
    "\n",
    "def layer_norm_config(cfg: Config):\n",
    "    return {\"epsilon\": cfg.layer_norm_eps}\n",
    "\n",
    "\n",
    "def translate_layer_norm_params(_cfg, params):\n",
    "    return {\"w\": params[\"scale\"], \"b\": params[\"bias\"]}\n",
    "\n",
    "\n",
    "rand_float_test(LayerNorm, [2, 4, 768])\n",
    "load_gpt2_test(\n",
    "    cls=LayerNorm,\n",
    "    ref_cls=tx.modules.LayerNorm,\n",
    "    ref_cfg={\"epsilon\": ex_cfg.layer_norm_eps},\n",
    "    variables={\"params\": translate_layer_norm_params(ex_cfg, gpt2_params[\"ln_f\"])},\n",
    "    ref_vars={\"params\": gpt2_params[\"ln_f\"]},\n",
    "    x=jnp.expand_dims(state[\"intermediates\"][\"residual\"][-1], axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 4)\n",
      "Output shape: (2, 4, 768) \n",
      "\n",
      "Input shape: (1, 45)\n",
      "Output shape: (1, 45, 768)\n",
      "Reference output shape: (1, 45, 768) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Embed(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        self.W_E = self.param(\n",
    "            \"W_E\",\n",
    "            nn.initializers.normal(stddev=self.cfg.init_range),\n",
    "            (self.cfg.vocab_dim, self.cfg.model_dim),\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, tokens: Int[Array, \"batch seq\"]\n",
    "    ) -> Float[Array, \"batch seq model\"]:\n",
    "        return self.W_E[tokens]\n",
    "\n",
    "\n",
    "def embed_config(cfg: Config):\n",
    "    return {\n",
    "        \"num_embeddings\": cfg.vocab_dim,\n",
    "        \"features\": cfg.model_dim,\n",
    "        \"init_range\": cfg.init_range,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_embed_params(_cfg, params):\n",
    "    return {\"W_E\": params[\"embedding\"]}\n",
    "\n",
    "\n",
    "rand_int_test(Embed, [2, 4])\n",
    "load_gpt2_test(\n",
    "    cls=Embed,\n",
    "    ref_cls=tx.modules.Embed,\n",
    "    ref_cfg=embed_config(ex_cfg),\n",
    "    variables={\"params\": translate_embed_params(ex_cfg, gpt2_params[\"embed\"])},\n",
    "    ref_vars={\"params\": gpt2_params[\"embed\"]},\n",
    "    x=jnp.expand_dims(tokens, axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 4)\n",
      "Output shape: (2, 4, 768) \n",
      "\n",
      "Input shape: (1, 45)\n",
      "Output shape: (1, 45, 768)\n",
      "Reference output shape: (1, 45, 768) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PosEmbed(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        self.W_pos = self.param(\n",
    "            \"W_pos\",\n",
    "            nn.initializers.normal(stddev=self.cfg.init_range),\n",
    "            (self.cfg.context_length, self.cfg.model_dim),\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, tokens: Int[Array, \"batch seq\"]\n",
    "    ) -> Float[Array, \"batch seq model\"]:\n",
    "        batch, seq_len = tokens.shape\n",
    "        return einops.repeat(\n",
    "            self.W_pos[:seq_len], \"seq model -> batch seq model\", batch=batch\n",
    "        )\n",
    "\n",
    "\n",
    "def pos_embed_config(cfg: Config):\n",
    "    return {\n",
    "        \"num_embeddings\": cfg.context_length,\n",
    "        \"features\": cfg.model_dim,\n",
    "        \"init_range\": cfg.init_range,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_pos_embed_params(_cfg, params):\n",
    "    return {\"W_pos\": params[\"embedding\"]}\n",
    "\n",
    "\n",
    "rand_int_test(PosEmbed, [2, 4])\n",
    "load_gpt2_test(\n",
    "    cls=PosEmbed,\n",
    "    ref_cls=tx.modules.PosEmbed,\n",
    "    ref_cfg=pos_embed_config(ex_cfg),\n",
    "    variables={\"params\": translate_pos_embed_params(ex_cfg, gpt2_params[\"pos_embed\"])},\n",
    "    ref_vars={\"params\": gpt2_params[\"pos_embed\"]},\n",
    "    x=jnp.expand_dims(tokens, axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 4, 768)\n",
      "Output shape: (2, 4, 768) \n",
      "\n",
      "Input shape: (1, 35, 768)\n",
      "Output shape: (1, 35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "(35, 768)\n",
      "Reference output shape: (1, 35, 768) \n",
      "\n",
      "0.10% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        init_fn = nn.initializers.normal(stddev=self.cfg.init_range)\n",
    "        qkv_kernel_shape = (self.cfg.num_heads, self.cfg.model_dim, self.cfg.head_dim)\n",
    "        self.W_Q = self.param(\"W_Q\", init_fn, qkv_kernel_shape)\n",
    "        self.W_K = self.param(\"W_K\", init_fn, qkv_kernel_shape)\n",
    "        self.W_V = self.param(\"W_V\", init_fn, qkv_kernel_shape)\n",
    "        self.W_O = self.param(\n",
    "            \"W_O\",\n",
    "            init_fn,\n",
    "            (qkv_kernel_shape[0], qkv_kernel_shape[2], qkv_kernel_shape[1]),\n",
    "        )\n",
    "\n",
    "        qkv_bias_shape = (self.cfg.num_heads, self.cfg.head_dim)\n",
    "        self.b_Q = self.param(\"b_Q\", nn.initializers.zeros, qkv_bias_shape)\n",
    "        self.b_K = self.param(\"b_K\", nn.initializers.zeros, qkv_bias_shape)\n",
    "        self.b_V = self.param(\"b_V\", nn.initializers.zeros, qkv_bias_shape)\n",
    "        self.b_O = self.param(\"b_O\", nn.initializers.zeros, (self.cfg.model_dim,))\n",
    "\n",
    "        self.IGNORE = jnp.array(-1e5, dtype=jnp.float32)\n",
    "\n",
    "    def __call__(\n",
    "        self, normalized_resid_pre: Float[Array, \"batch seq model\"]\n",
    "    ) -> Float[Array, \"batch seq model\"]:\n",
    "        # Calculate query, key and value vectors\n",
    "        q = (\n",
    "            einops.einsum(\n",
    "                normalized_resid_pre,\n",
    "                self.W_Q,\n",
    "                \"batch seq model, n_head model h_dim -> batch seq n_head h_dim\",\n",
    "            )\n",
    "            + self.b_Q\n",
    "        )\n",
    "        # print(q.shape)\n",
    "        k = (\n",
    "            einops.einsum(\n",
    "                normalized_resid_pre,\n",
    "                self.W_K,\n",
    "                \"batch seq model, n_head model h_dim -> batch seq n_head h_dim\",\n",
    "            )\n",
    "            + self.b_K\n",
    "        )\n",
    "        v = (\n",
    "            einops.einsum(\n",
    "                normalized_resid_pre,\n",
    "                self.W_V,\n",
    "                \"batch seq model, n_head model h_dim -> batch seq n_head h_dim\",\n",
    "            )\n",
    "            + self.b_V\n",
    "        )\n",
    "\n",
    "        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
    "        attn_scores = einops.einsum(\n",
    "            q,\n",
    "            k,\n",
    "            \"batch seq_q n_head h_dim, batch seq_k n_head h_dim -> batch n_head seq_q seq_k\",\n",
    "        )\n",
    "        attn_scores_masked = self.apply_causal_mask(\n",
    "            attn_scores / self.cfg.head_dim**0.5\n",
    "        )\n",
    "        attn_pattern = jax.nn.softmax(attn_scores_masked, axis=-1)\n",
    "\n",
    "        # Take weighted sum of value vectors, according to attention probabilities\n",
    "        z = einops.einsum(\n",
    "            v,\n",
    "            attn_pattern,\n",
    "            \"batch seq_k n_head h_dim, batch n_head seq_q seq_k -> batch seq_q n_head h_dim\",\n",
    "        )\n",
    "\n",
    "        # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
    "        attn_out = (\n",
    "            einops.einsum(\n",
    "                z,\n",
    "                self.W_O,\n",
    "                \"batch seq_q n_head h_dim, n_head h_dim model -> batch seq_q model\",\n",
    "            )\n",
    "            + self.b_O\n",
    "        )\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "    def apply_causal_mask(\n",
    "        self, attn_scores: Float[Array, \"batch n_head seq_q seq_k\"]\n",
    "    ) -> Float[Array, \"batch n_head seq_q seq_k\"]:\n",
    "        \"\"\"\n",
    "        Applies a causal mask to attention scores, and returns masked scores.\n",
    "        \"\"\"\n",
    "        # Define a mask that is True for all positions we want to set probabilities to zero for\n",
    "        all_ones = jnp.ones((attn_scores.shape[-2], attn_scores.shape[-1]))\n",
    "        mask = jnp.triu(all_ones, k=1)\n",
    "        # Apply the mask to attention scores, then return the masked scores\n",
    "        # attn_scores.masked_fill_(mask, self.IGNORE)\n",
    "        attn_scores = jnp.where(mask, self.IGNORE, attn_scores)\n",
    "        return attn_scores\n",
    "\n",
    "\n",
    "rand_float_test(Attention, [2, 4, 768])\n",
    "\n",
    "\n",
    "def attn_config(cfg: Config):\n",
    "    return {\n",
    "        \"num_heads\": cfg.num_heads,\n",
    "        \"head_dim\": cfg.head_dim,\n",
    "        \"model_dim\": cfg.model_dim,\n",
    "        \"context_length\": cfg.context_length,\n",
    "        \"init_range\": cfg.init_range,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_attn_params(cfg: Config, params):\n",
    "    q_kernel, k_kernel, v_kernel = jnp.split(params[\"c_attn\"][\"kernel\"], 3, axis=-1)\n",
    "    q_bias, k_bias, v_bias = jnp.split(params[\"c_attn\"][\"bias\"], 3, axis=-1)\n",
    "\n",
    "    rs_1 = lambda x: jnp.reshape(x, (cfg.num_heads, cfg.model_dim, cfg.head_dim))\n",
    "    rs_2 = lambda x: jnp.reshape(x, (cfg.num_heads, cfg.head_dim))\n",
    "    rs_3 = lambda x: jnp.reshape(x, (cfg.num_heads, cfg.head_dim, cfg.model_dim))\n",
    "\n",
    "    q_kernel, k_kernel, v_kernel = rs_1(q_kernel), rs_1(k_kernel), rs_1(v_kernel)\n",
    "    q_bias, k_bias, v_bias = rs_2(q_bias), rs_2(k_bias), rs_2(v_bias)\n",
    "    o_kernel, o_bias = rs_3(params[\"c_proj\"][\"kernel\"]), params[\"c_proj\"][\"bias\"]\n",
    "\n",
    "    return {\n",
    "        \"W_Q\": q_kernel,\n",
    "        \"W_K\": k_kernel,\n",
    "        \"W_V\": v_kernel,\n",
    "        \"W_O\": o_kernel,\n",
    "        \"b_Q\": q_bias,\n",
    "        \"b_K\": k_bias,\n",
    "        \"b_V\": v_bias,\n",
    "        \"b_O\": o_bias,\n",
    "    }\n",
    "\n",
    "\n",
    "load_gpt2_test(\n",
    "    cls=Attention,\n",
    "    ref_cls=tx.modules.Attention,\n",
    "    ref_cfg=attn_config(ex_cfg),\n",
    "    variables={\"params\": translate_attn_params(ex_cfg, gpt2_params[\"block_0\"][\"attn\"])},\n",
    "    ref_vars={\"params\": gpt2_params[\"block_0\"][\"attn\"]},\n",
    "    x=jnp.expand_dims(state[\"intermediates\"][\"block_0\"][\"ln_1_output\"][0], axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        init_fn = nn.initializers.normal(stddev=self.cfg.init_range)\n",
    "        self.W_in = self.param(\"W_in\", init_fn, (self.cfg.model_dim, self.cfg.mlp_dim))\n",
    "        self.W_out = self.param(\n",
    "            \"W_out\", init_fn, (self.cfg.mlp_dim, self.cfg.model_dim)\n",
    "        )\n",
    "        self.b_in = self.param(\"b_in\", nn.initializers.zeros, (self.cfg.mlp_dim,))\n",
    "        self.b_out = self.param(\"b_out\", nn.initializers.zeros, (self.cfg.model_dim,))\n",
    "        self.IGNORE = jnp.array(-1e5, dtype=jnp.float32)\n",
    "\n",
    "    def __call__(\n",
    "        self, normalized_resid_mid: Float[Array, \"batch seq model\"]\n",
    "    ) -> Float[Array, \"batch seq model\"]:\n",
    "        pre = (\n",
    "            einops.einsum(\n",
    "                normalized_resid_mid,\n",
    "                self.W_in,\n",
    "                \"batch seq model, model mlp -> batch seq mlp\",\n",
    "            )\n",
    "            + self.b_in\n",
    "        )\n",
    "        post = nn.gelu(pre)\n",
    "        mlp_out = (\n",
    "            einops.einsum(\n",
    "                post,\n",
    "                self.W_out,\n",
    "                \"batch seq mlp, mlp model -> batch seq model\",\n",
    "            )\n",
    "            + self.b_out\n",
    "        )\n",
    "        return mlp_out\n",
    "\n",
    "\n",
    "def mlp_config(cfg: Config):\n",
    "    return {\n",
    "        \"features\": [cfg.mlp_dim, cfg.model_dim],\n",
    "        \"init_range\": cfg.init_range,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_mlp_params(_cfg, params):\n",
    "    return {\n",
    "        \"W_in\": params[\"fc_1\"][\"kernel\"],\n",
    "        \"W_out\": params[\"proj\"][\"kernel\"],\n",
    "        \"b_in\": params[\"fc_1\"][\"bias\"],\n",
    "        \"b_out\": params[\"proj\"][\"bias\"],\n",
    "    }\n",
    "\n",
    "\n",
    "rand_float_test(MLP, [2, 4, 768])\n",
    "load_gpt2_test(\n",
    "    cls=MLP,\n",
    "    ref_cls=tx.modules.MLP,\n",
    "    ref_cfg=mlp_config(ex_cfg),\n",
    "    variables={\"params\": translate_mlp_params(ex_cfg, gpt2_params[\"block_0\"][\"mlp\"])},\n",
    "    ref_vars={\"params\": gpt2_params[\"block_0\"][\"mlp\"]},\n",
    "    x=jnp.expand_dims(state[\"intermediates\"][\"block_0\"][\"ln_2_output\"][0], axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        self.ln1 = LayerNorm(self.cfg)\n",
    "        self.attn = Attention(self.cfg)\n",
    "        self.ln2 = LayerNorm(self.cfg)\n",
    "        self.mlp = MLP(self.cfg)\n",
    "\n",
    "    def __call__(\n",
    "        self, resid_pre: Float[Array, \"batch seq model\"]\n",
    "    ) -> Float[Array, \"batch seq model\"]:\n",
    "        resid_mid = self.attn(self.ln1(resid_pre)) + resid_pre\n",
    "        resid_post = self.mlp(self.ln2(resid_mid)) + resid_mid\n",
    "        return resid_post\n",
    "\n",
    "\n",
    "def block_config(cfg: Config):\n",
    "    return {\n",
    "        \"model_dim\": cfg.model_dim,\n",
    "        \"mlp_dim\": cfg.mlp_dim,\n",
    "        \"num_heads\": cfg.num_heads,\n",
    "        \"head_dim\": cfg.head_dim,\n",
    "        \"context_length\": cfg.context_length,\n",
    "        \"init_range\": cfg.init_range,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_block_params(cfg: Config, params):\n",
    "    return {\n",
    "        \"ln1\": translate_layer_norm_params(cfg, params[\"ln_1\"]),\n",
    "        \"attn\": translate_attn_params(cfg, params[\"attn\"]),\n",
    "        \"ln2\": translate_layer_norm_params(cfg, params[\"ln_2\"]),\n",
    "        \"mlp\": translate_mlp_params(cfg, params[\"mlp\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "rand_float_test(TransformerBlock, [2, 4, 768])\n",
    "load_gpt2_test(\n",
    "    cls=TransformerBlock,\n",
    "    ref_cls=tx.modules.TransformerBlock,\n",
    "    ref_cfg=block_config(ex_cfg),\n",
    "    variables={\"params\": translate_block_params(ex_cfg, gpt2_params[\"block_0\"])},\n",
    "    ref_vars={\"params\": gpt2_params[\"block_0\"]},\n",
    "    x=jnp.expand_dims(state[\"intermediates\"][\"block_0\"][\"ln_2_output\"][0], axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unembed(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        init_fn = nn.initializers.normal(stddev=self.cfg.init_range)\n",
    "        self.W_U = self.param(\"W_U\", init_fn, (self.cfg.model_dim, self.cfg.vocab_dim))\n",
    "        self.b_U = self.param(\"b_U\", nn.initializers.zeros, (self.cfg.vocab_dim,))\n",
    "\n",
    "    def __call__(\n",
    "        self, normalized_resid_final: Float[Array, \"batch seq model\"]\n",
    "    ) -> Float[Array, \"batch seq vocab\"]:\n",
    "        return (\n",
    "            einops.einsum(\n",
    "                normalized_resid_final,\n",
    "                self.W_U,\n",
    "                \"batch seq model, model vocab -> batch seq vocab\",\n",
    "            )\n",
    "            + self.b_U\n",
    "        )\n",
    "        # Or, could just do `normalized_resid_final @ self.W_U + self.b_U`\n",
    "\n",
    "\n",
    "def unembed_config(cfg: Config):\n",
    "    return {\n",
    "        \"num_embeddings\": cfg.vocab_dim,\n",
    "        \"features\": cfg.model_dim,\n",
    "        \"init_range\": cfg.init_range,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_unembed_params(_cfg, params):\n",
    "    return {\"W_U\": params[\"kernel\"], \"b_U\": params[\"bias\"]}\n",
    "\n",
    "\n",
    "rand_float_test(Unembed, [2, 4, 768])\n",
    "\n",
    "load_gpt2_test(\n",
    "    cls=Unembed,\n",
    "    ref_cls=tx.modules.Unembed,\n",
    "    ref_cfg=unembed_config(ex_cfg),\n",
    "    variables={\"params\": translate_unembed_params(ex_cfg, gpt2_params[\"unembed\"])},\n",
    "    ref_vars={\"params\": gpt2_params[\"unembed\"]},\n",
    "    x=jnp.expand_dims(state[\"intermediates\"][\"final_output\"][0], axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoTransformer(nn.Module):\n",
    "    cfg: Config\n",
    "\n",
    "    def setup(self):\n",
    "        self.embed = Embed(self.cfg)\n",
    "        self.pos_embed = PosEmbed(self.cfg)\n",
    "        self.blocks = [\n",
    "            TransformerBlock(name=f\"block_{i}\", cfg=self.cfg)\n",
    "            for i in range(self.cfg.num_layers)\n",
    "        ]\n",
    "        self.ln_final = LayerNorm(self.cfg)\n",
    "        self.unembed = Unembed(self.cfg)\n",
    "\n",
    "    def __call__(\n",
    "        self, tokens: Int[Array, \"batch seq\"]\n",
    "    ) -> Float[Array, \"batch seq vocab\"]:\n",
    "        residual = self.embed(tokens) + self.pos_embed(tokens)\n",
    "        for block in self.blocks:\n",
    "            residual = block(residual)\n",
    "        logits = self.unembed(self.ln_final(residual))\n",
    "        return logits\n",
    "\n",
    "\n",
    "def transformer_config(cfg: Config):\n",
    "    return {\n",
    "        \"vocab_dim\": cfg.vocab_dim,\n",
    "        \"model_dim\": cfg.model_dim,\n",
    "        \"mlp_dim\": cfg.mlp_dim,\n",
    "        \"num_heads\": cfg.num_heads,\n",
    "        \"head_dim\": cfg.head_dim,\n",
    "        \"context_length\": cfg.context_length,\n",
    "        \"init_range\": cfg.init_range,\n",
    "        \"num_layers\": cfg.num_layers,\n",
    "    }\n",
    "\n",
    "\n",
    "def translate_transformer_params(cfg: Config, params):\n",
    "    return {\n",
    "        \"embed\": translate_embed_params(cfg, params[\"embed\"]),\n",
    "        \"pos_embed\": translate_pos_embed_params(cfg, params[\"pos_embed\"]),\n",
    "        \"ln_final\": translate_layer_norm_params(cfg, params[\"ln_f\"]),\n",
    "        \"unembed\": translate_unembed_params(cfg, params[\"unembed\"]),\n",
    "        **{\n",
    "            f\"block_{i}\": translate_block_params(cfg, params[f\"block_{i}\"])\n",
    "            for i in range(cfg.num_layers)\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "rand_int_test(DemoTransformer, [2, 4])\n",
    "load_gpt2_test(\n",
    "    cls=DemoTransformer,\n",
    "    ref_cls=tx.modules.Transformer,\n",
    "    ref_cfg=transformer_config(ex_cfg),\n",
    "    variables={\"params\": translate_transformer_params(ex_cfg, gpt2_params)},\n",
    "    ref_vars={\"params\": gpt2_params},\n",
    "    x=jnp.expand_dims(tokens, axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_cfg = Config(debug=False)\n",
    "demo_gpt2 = DemoTransformer(demo_cfg)\n",
    "# demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
    "\n",
    "demo_logits = demo_gpt2.apply(\n",
    "    {\"params\": translate_transformer_params(demo_cfg, gpt2_params)},\n",
    "    jnp.expand_dims(tokens, axis=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_probs(\n",
    "    logits: Float[Array, \"batch seq vocab\"], tokens: Int[Array, \"batch seq\"]\n",
    ") -> Float[Array, \"batch seq-1\"]:\n",
    "    log_probs = jax.nn.log_softmax(logits, axis=-1)\n",
    "    # Get logprobs the first seq_len-1 predictions (so we can compare them with the actual next tokens)\n",
    "    expanded_tokens = jnp.expand_dims(tokens[:, 1:], axis=-1)\n",
    "    y = jnp.take_along_axis(log_probs[:, :-1], expanded_tokens, axis=-1)\n",
    "    return jnp.squeeze(y, axis=-1)\n",
    "\n",
    "\n",
    "pred_log_probs = get_log_probs(demo_logits, jnp.expand_dims(tokens, axis=0))\n",
    "print(f\"Avg cross entropy loss: {-pred_log_probs.mean():.4f}\")\n",
    "print(\n",
    "    f\"Avg cross entropy loss for uniform distribution: {math.log(demo_gpt2.cfg.vocab_dim):4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Avg probability assigned to correct token: {jnp.mean(jnp.exp(pred_log_probs)):4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"The Total Perspective Vortex derives its picture of the whole Universe on the principle of\"\"\"\n",
    "for i in tqdm(range(10)):\n",
    "    test_tokens = jnp.expand_dims(reference_gpt2.to_tokens(test_string), axis=0)\n",
    "    demo_logits = demo_gpt2.apply(\n",
    "        {\"params\": translate_transformer_params(demo_cfg, gpt2_params)}, test_tokens\n",
    "    )\n",
    "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
    "\n",
    "print(test_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b805f1a24a146351cd8dedea7ba6f2d165b63b34e3029cd12d1a8f2ce65f719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
